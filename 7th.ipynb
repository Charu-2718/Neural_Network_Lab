{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Adrj0NiBn35m",
        "outputId": "b88de64e-6ee4-4e36-f21b-3426bac3ea59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Mean Squared Error: 1.3758377894004639\n",
            "Epoch 100, Mean Squared Error: 0.7018801013607125\n",
            "Epoch 200, Mean Squared Error: 0.6928619142346069\n",
            "Epoch 300, Mean Squared Error: 0.6881145373542634\n",
            "Epoch 400, Mean Squared Error: 0.6855725424496906\n",
            "Epoch 500, Mean Squared Error: 0.6839623519586129\n",
            "Epoch 600, Mean Squared Error: 0.6827742329965771\n",
            "Epoch 700, Mean Squared Error: 0.6817532604638251\n",
            "Epoch 800, Mean Squared Error: 0.6807078085994149\n",
            "Epoch 900, Mean Squared Error: 0.6794964374236431\n",
            "Epoch 1000, Mean Squared Error: 0.6781823318934601\n",
            "Epoch 1100, Mean Squared Error: 0.6770105526384759\n",
            "Epoch 1200, Mean Squared Error: 0.6760673927442369\n",
            "Epoch 1300, Mean Squared Error: 0.6752936023158608\n",
            "Epoch 1400, Mean Squared Error: 0.6746310058002283\n",
            "Epoch 1500, Mean Squared Error: 0.6740452592887057\n",
            "Epoch 1600, Mean Squared Error: 0.6735143164701546\n",
            "Epoch 1700, Mean Squared Error: 0.6730214031587322\n",
            "Epoch 1800, Mean Squared Error: 0.6725536625281524\n",
            "Epoch 1900, Mean Squared Error: 0.67210401346719\n",
            "Epoch 2000, Mean Squared Error: 0.6716708770041101\n",
            "Epoch 2100, Mean Squared Error: 0.6712507017729726\n",
            "Epoch 2200, Mean Squared Error: 0.6708270741611028\n",
            "Epoch 2300, Mean Squared Error: 0.6703570799590751\n",
            "Epoch 2400, Mean Squared Error: 0.6697320719659035\n",
            "Epoch 2500, Mean Squared Error: 0.6686968320755299\n",
            "Epoch 2600, Mean Squared Error: 0.6671430904759424\n",
            "Epoch 2700, Mean Squared Error: 0.6657430864641095\n",
            "Epoch 2800, Mean Squared Error: 0.6646571018881222\n",
            "Epoch 2900, Mean Squared Error: 0.6637705470524887\n",
            "Epoch 3000, Mean Squared Error: 0.6630167042285637\n",
            "Epoch 3100, Mean Squared Error: 0.6623585947394788\n",
            "Epoch 3200, Mean Squared Error: 0.6617731151672936\n",
            "Epoch 3300, Mean Squared Error: 0.6612442213833987\n",
            "Epoch 3400, Mean Squared Error: 0.6607615008788675\n",
            "Epoch 3500, Mean Squared Error: 0.6603188553920559\n",
            "Epoch 3600, Mean Squared Error: 0.6599127543888086\n",
            "Epoch 3700, Mean Squared Error: 0.6595405959773575\n",
            "Epoch 3800, Mean Squared Error: 0.6591997092116173\n",
            "Epoch 3900, Mean Squared Error: 0.6588871295841789\n",
            "Epoch 4000, Mean Squared Error: 0.6585998099158721\n",
            "Epoch 4100, Mean Squared Error: 0.6583348803546162\n",
            "Epoch 4200, Mean Squared Error: 0.6580898002272936\n",
            "Epoch 4300, Mean Squared Error: 0.6578624004055189\n",
            "Epoch 4400, Mean Squared Error: 0.6576508548395172\n",
            "Epoch 4500, Mean Squared Error: 0.6574536189578771\n",
            "Epoch 4600, Mean Squared Error: 0.6572693636611876\n",
            "Epoch 4700, Mean Squared Error: 0.6570969216930945\n",
            "Epoch 4800, Mean Squared Error: 0.6569352513480137\n",
            "Epoch 4900, Mean Squared Error: 0.6567834146594604\n",
            "Epoch 5000, Mean Squared Error: 0.6566405645784312\n",
            "Epoch 5100, Mean Squared Error: 0.6565059364637298\n",
            "Epoch 5200, Mean Squared Error: 0.6563788411086408\n",
            "Epoch 5300, Mean Squared Error: 0.6562586581164025\n",
            "Epoch 5400, Mean Squared Error: 0.6561448293445777\n",
            "Epoch 5500, Mean Squared Error: 0.6560368525116106\n",
            "Epoch 5600, Mean Squared Error: 0.6559342751392928\n",
            "Epoch 5700, Mean Squared Error: 0.6558366889669462\n",
            "Epoch 5800, Mean Squared Error: 0.6557437249081095\n",
            "Epoch 5900, Mean Squared Error: 0.6556550485648082\n",
            "Epoch 6000, Mean Squared Error: 0.65557035627708\n",
            "Epoch 6100, Mean Squared Error: 0.6554893716645532\n",
            "Epoch 6200, Mean Squared Error: 0.6554118426078772\n",
            "Epoch 6300, Mean Squared Error: 0.6553375386163312\n",
            "Epoch 6400, Mean Squared Error: 0.6552662485306842\n",
            "Epoch 6500, Mean Squared Error: 0.6551977785151978\n",
            "Epoch 6600, Mean Squared Error: 0.6551319502981982\n",
            "Epoch 6700, Mean Squared Error: 0.6550685996261612\n",
            "Epoch 6800, Mean Squared Error: 0.6550075749013523\n",
            "Epoch 6900, Mean Squared Error: 0.6549487359775853\n",
            "Epoch 7000, Mean Squared Error: 0.6548919530925693\n",
            "Epoch 7100, Mean Squared Error: 0.6548371059186391\n",
            "Epoch 7200, Mean Squared Error: 0.6547840827164535\n",
            "Epoch 7300, Mean Squared Error: 0.6547327795785857\n",
            "Epoch 7400, Mean Squared Error: 0.6546830997518739\n",
            "Epoch 7500, Mean Squared Error: 0.654634953029035\n",
            "Epoch 7600, Mean Squared Error: 0.6545882552013882\n",
            "Epoch 7700, Mean Squared Error: 0.6545429275656828\n",
            "Epoch 7800, Mean Squared Error: 0.6544988964789631\n",
            "Epoch 7900, Mean Squared Error: 0.6544560929562215\n",
            "Epoch 8000, Mean Squared Error: 0.6544144523062533\n",
            "Epoch 8100, Mean Squared Error: 0.6543739138017143\n",
            "Epoch 8200, Mean Squared Error: 0.6543344203798678\n",
            "Epoch 8300, Mean Squared Error: 0.6542959183709309\n",
            "Epoch 8400, Mean Squared Error: 0.654258357251284\n",
            "Epoch 8500, Mean Squared Error: 0.6542216894191275\n",
            "Epoch 8600, Mean Squared Error: 0.6541858699904265\n",
            "Epoch 8700, Mean Squared Error: 0.6541508566132256\n",
            "Epoch 8800, Mean Squared Error: 0.654116609298604\n",
            "Epoch 8900, Mean Squared Error: 0.6540830902667292\n",
            "Epoch 9000, Mean Squared Error: 0.6540502638066025\n",
            "Epoch 9100, Mean Squared Error: 0.6540180961482324\n",
            "Epoch 9200, Mean Squared Error: 0.6539865553460751\n",
            "Epoch 9300, Mean Squared Error: 0.6539556111726873\n",
            "Epoch 9400, Mean Squared Error: 0.6539252350216204\n",
            "Epoch 9500, Mean Squared Error: 0.6538953998186525\n",
            "Epoch 9600, Mean Squared Error: 0.6538660799405378\n",
            "Epoch 9700, Mean Squared Error: 0.6538372511404914\n",
            "Epoch 9800, Mean Squared Error: 0.653808890479699\n",
            "Epoch 9900, Mean Squared Error: 0.6537809762641784\n",
            "\n",
            "Final predictions:\n",
            "[[4.42942217e-01]\n",
            " [2.03944340e-02]\n",
            " [1.70115975e-06]\n",
            " [1.07699914e-03]\n",
            " [1.52911221e-05]\n",
            " [6.07684223e-01]\n",
            " [9.78632947e-01]\n",
            " [9.99701092e-01]\n",
            " [9.79738981e-01]\n",
            " [1.02301355e-05]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Define the sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Define the derivative of the sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Normalize the inputs\n",
        "def normalize(data):\n",
        "    mean = np.mean(data, axis=0)\n",
        "    std = np.std(data, axis=0)\n",
        "    return (data - mean) / std\n",
        "\n",
        "# Define the neural network class\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        # Initialize weights and biases with random values\n",
        "        self.weights_input_hidden = np.random.rand(input_size, hidden_size)\n",
        "        self.bias_hidden = np.zeros((1, hidden_size))\n",
        "        self.weights_hidden_output = np.random.rand(hidden_size, output_size)\n",
        "        self.bias_output = np.zeros((1, output_size))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Perform forward pass\n",
        "        self.hidden_layer_input = np.dot(inputs, self.weights_input_hidden)\n",
        "        self.hidden_layer_output = sigmoid(self.hidden_layer_input + self.bias_hidden)\n",
        "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output)\n",
        "        self.output = sigmoid(self.output_layer_input + self.bias_output)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, inputs, targets, learning_rate):\n",
        "        # Perform backward pass and update weights and biases\n",
        "\n",
        "        # Calculate the error\n",
        "        output_error = targets - self.output\n",
        "\n",
        "        # Calculate gradients for output layer\n",
        "        output_delta = output_error * sigmoid_derivative(self.output)\n",
        "        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
        "\n",
        "        # Calculate gradients for hidden layer\n",
        "        hidden_delta = hidden_error * sigmoid_derivative(self.hidden_layer_output)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights_hidden_output += self.hidden_layer_output.T.dot(output_delta) * learning_rate\n",
        "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
        "        self.weights_input_hidden += inputs.T.dot(hidden_delta) * learning_rate\n",
        "        self.bias_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    def train(self, inputs, targets, epochs, learning_rate):\n",
        "        # Train the neural network for a specified number of epochs\n",
        "        for epoch in range(epochs):\n",
        "            # Forward pass\n",
        "            output = self.forward(inputs)\n",
        "\n",
        "            # Backward pass and weight update\n",
        "            self.backward(inputs, targets, learning_rate)\n",
        "\n",
        "            # Calculate and print the mean squared error for monitoring\n",
        "            mse = np.mean(np.square(targets - output))\n",
        "            if epoch % 100 == 0:\n",
        "                print(f\"Epoch {epoch}, Mean Squared Error: {mse}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load your dataset \n",
        "    dataset_path = \"House_Price.csv\"\n",
        "    data = pd.read_csv(dataset_path)\n",
        "    # Extract features and target variable\n",
        "    features = data.iloc[:, 1:].values\n",
        "    target = data.iloc[:, 0].values.reshape(-1, 1)\n",
        "\n",
        "    # Normalize features and target variable\n",
        "    normalized_features = normalize(features)\n",
        "    normalized_target = (target - np.mean(target)) / np.std(target)\n",
        "\n",
        "    # Define input, target data, and hyperparameters\n",
        "    input_size = normalized_features.shape[1]\n",
        "    hidden_size = 4\n",
        "    output_size = 1\n",
        "    epochs = 10000\n",
        "    learning_rate = 0.01  # Adjust the learning rate\n",
        "\n",
        "    # Create and train the neural network\n",
        "    neural_network = NeuralNetwork(input_size, hidden_size, output_size)\n",
        "    neural_network.train(normalized_features, normalized_target, epochs, learning_rate)\n",
        "\n",
        "    # Test the trained neural network (replace this with your testing code)\n",
        "    test_features = np.random.rand(10, input_size)\n",
        "    normalized_test_features = normalize(test_features)\n",
        "    predictions = neural_network.forward(normalized_test_features)\n",
        "    print(\"\\nFinal predictions:\")\n",
        "    print(predictions)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
